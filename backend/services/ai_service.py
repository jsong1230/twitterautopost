from typing import List, Dict, Optional
import json
import logging
import hashlib
import asyncio
from functools import wraps
from datetime import datetime, timedelta
from backend.config import settings
from backend.services.ai_models import InsightResponse, TweetResponse, InstagramPostResponse

logger = logging.getLogger(__name__)

# ê°„ë‹¨í•œ ì¸ë©”ëª¨ë¦¬ ìºì‹œ
_cache = {}
_cache_timestamps = {}


def cache_response(ttl: int = None):
    """ì‘ë‹µ ìºì‹± ë°ì½”ë ˆì´í„°"""
    if ttl is None:
        ttl = settings.ai_cache_ttl
    
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            # ìºì‹œ í‚¤ ìƒì„±
            cache_key = hashlib.md5(
                f"{func.__name__}:{str(args)}:{str(kwargs)}".encode()
            ).hexdigest()
            
            # ìºì‹œ í™•ì¸
            if cache_key in _cache:
                timestamp = _cache_timestamps.get(cache_key)
                if timestamp and (datetime.now() - timestamp).total_seconds() < ttl:
                    logger.info(f"ìºì‹œ íˆíŠ¸: {func.__name__}")
                    return _cache[cache_key]
                else:
                    # ë§Œë£Œëœ ìºì‹œ ì‚­ì œ
                    del _cache[cache_key]
                    del _cache_timestamps[cache_key]
            
            # ìºì‹œ ë¯¸ìŠ¤ - í•¨ìˆ˜ ì‹¤í–‰
            logger.info(f"ìºì‹œ ë¯¸ìŠ¤: {func.__name__}")
            result = await func(*args, **kwargs)
            
            # ê²°ê³¼ ìºì‹±
            _cache[cache_key] = result
            _cache_timestamps[cache_key] = datetime.now()
            
            return result
        return wrapper
    return decorator


async def retry_with_backoff(func, max_retries: int = None, timeout: int = None):
    """ì¬ì‹œë„ ë¡œì§ with exponential backoff"""
    if max_retries is None:
        max_retries = settings.ai_max_retries
    if timeout is None:
        timeout = settings.ai_timeout
    
    last_exception = None
    
    for attempt in range(max_retries):
        try:
            # íƒ€ì„ì•„ì›ƒ ì ìš©
            result = await asyncio.wait_for(func(), timeout=timeout)
            return result
        except asyncio.TimeoutError:
            last_exception = TimeoutError(f"API í˜¸ì¶œ íƒ€ì„ì•„ì›ƒ ({timeout}ì´ˆ)")
            logger.warning(f"íƒ€ì„ì•„ì›ƒ ë°œìƒ (ì‹œë„ {attempt + 1}/{max_retries})")
        except Exception as e:
            last_exception = e
            logger.warning(f"API í˜¸ì¶œ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/{max_retries}): {e}")
        
        # ë§ˆì§€ë§‰ ì‹œë„ê°€ ì•„ë‹ˆë©´ ëŒ€ê¸°
        if attempt < max_retries - 1:
            wait_time = 2 ** attempt  # exponential backoff: 1, 2, 4ì´ˆ
            logger.info(f"{wait_time}ì´ˆ í›„ ì¬ì‹œë„...")
            await asyncio.sleep(wait_time)
    
    # ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨
    raise last_exception


class AIService:
    def __init__(self):
        self.openai_api_key = settings.openai_api_key
        self.claude_api_key = settings.claude_api_key

    @cache_response()
    async def generate_insights(self, tweets: List[str]) -> Dict:
        """
        íŠ¸ìœ— ë¦¬ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ íŠ¸ë Œë“œ ìš”ì•½ ìƒì„±
        Returns: {summary_kr: str, summary_en: str}
        """
        if not tweets:
            return {
                "summary_kr": "ë¶„ì„í•  íŠ¸ìœ—ì´ ì—†ìŠµë‹ˆë‹¤.",
                "summary_en": "No tweets to analyze."
            }

        tweets_text = "\n".join(tweets[:20])  # ìƒìœ„ 20ê°œë§Œ ì‚¬ìš©
        
        # ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ - JSON ì‘ë‹µ ê°•ì œ
        prompt = f"""ë‹¤ìŒ íŠ¸ìœ—ë“¤ì„ ë¶„ì„í•˜ì—¬ ì£¼ìš” íŠ¸ë Œë“œë¥¼ ìš”ì•½í•´ì£¼ì„¸ìš”.

íŠ¸ìœ— ëª©ë¡:
{tweets_text}

ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
  "summary_kr": "í•œêµ­ì–´ë¡œ ì‘ì„±ëœ ì£¼ìš” íŠ¸ë Œë“œ ìš”ì•½ (3-5ê°œì˜ êµ¬ì²´ì ì¸ í¬ì¸íŠ¸)",
  "summary_en": "English summary of main trends (3-5 specific points)"
}}

ìš”ì•½ ì‘ì„± ê°€ì´ë“œ:
- êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì¸ì‚¬ì´íŠ¸ ì œê³µ
- ê°ì •ì  í†¤ê³¼ ì£¼ìš” í‚¤ì›Œë“œ íŒŒì•…
- íŠ¸ë Œë“œì˜ ë§¥ë½ê³¼ ì˜ë¯¸ ì„¤ëª…
- ê° ì–¸ì–´ë¡œ ë…ë¦½ì ìœ¼ë¡œ ì‘ì„± (ë‹¨ìˆœ ë²ˆì—­ X)"""

        try:
            # OpenAI API ì‹œë„
            if self.openai_api_key:
                result = await retry_with_backoff(
                    lambda: self._call_openai(prompt, model="gpt-4o-mini")
                )
                if result and "OpenAI API key" not in result:
                    parsed = self._parse_insights(result)
                    if parsed:
                        return parsed
            
            # Claude API ì‹œë„
            if self.claude_api_key:
                result = await retry_with_backoff(
                    lambda: self._call_claude(prompt, model="claude-3-5-sonnet-20241022")
                )
                if result and "Claude API key" not in result:
                    parsed = self._parse_insights(result)
                    if parsed:
                        return parsed
        except Exception as e:
            logger.error(f"AI API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)

        # API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ë”ë¯¸ ë°ì´í„° ë°˜í™˜
        logger.warning("AI API í˜¸ì¶œ ì‹¤íŒ¨, ë”ë¯¸ ë°ì´í„° ë°˜í™˜")
        return self._get_dummy_insights(len(tweets))
    
    def _parse_insights(self, text: str) -> Optional[Dict]:
        """AI ì‘ë‹µì—ì„œ í•œê¸€/ì˜ë¬¸ ìš”ì•½ íŒŒì‹± (JSON ìš°ì„ )"""
        try:
            # JSON íŒŒì‹± ì‹œë„
            # ì½”ë“œ ë¸”ë¡ ì œê±°
            text = text.strip()
            if "```json" in text:
                text = text.split("```json")[1].split("```")[0].strip()
            elif "```" in text:
                text = text.split("```")[1].split("```")[0].strip()
            
            data = json.loads(text)
            
            # Pydantic ëª¨ë¸ë¡œ ê²€ì¦
            validated = InsightResponse(**data)
            return {
                "summary_kr": validated.summary_kr,
                "summary_en": validated.summary_en
            }
        except (json.JSONDecodeError, ValueError) as e:
            logger.warning(f"JSON íŒŒì‹± ì‹¤íŒ¨, í…ìŠ¤íŠ¸ íŒŒì‹± ì‹œë„: {e}")
            # í´ë°±: í…ìŠ¤íŠ¸ ê¸°ë°˜ íŒŒì‹±
            return self._parse_insights_text(text)
    
    def _parse_insights_text(self, text: str) -> Optional[Dict]:
        """í…ìŠ¤íŠ¸ ê¸°ë°˜ íŒŒì‹± (í´ë°±)"""
        summary_kr = ""
        summary_en = ""
        
        # í•œê¸€ ìš”ì•½ ì¶”ì¶œ
        if "summary_kr" in text:
            parts = text.split('"summary_kr"')
            if len(parts) > 1:
                summary_kr = parts[1].split('"summary_en"')[0].strip(' :,"')
        elif "í•œê¸€ ìš”ì•½:" in text or "í•œêµ­ì–´" in text:
            parts = text.split("í•œê¸€ ìš”ì•½:") if "í•œê¸€ ìš”ì•½:" in text else text.split("í•œêµ­ì–´")
            if len(parts) > 1:
                summary_kr = parts[1].split("ì˜ë¬¸ ìš”ì•½:")[0].split("ì˜ì–´")[0].strip()
        
        # ì˜ë¬¸ ìš”ì•½ ì¶”ì¶œ
        if "summary_en" in text:
            parts = text.split('"summary_en"')
            if len(parts) > 1:
                summary_en = parts[1].strip(' :,"{}')
        elif "ì˜ë¬¸ ìš”ì•½:" in text or "ì˜ì–´" in text:
            parts = text.split("ì˜ë¬¸ ìš”ì•½:") if "ì˜ë¬¸ ìš”ì•½:" in text else text.split("ì˜ì–´")
            if len(parts) > 1:
                summary_en = parts[-1].strip()
        
        # ê²€ì¦
        if summary_kr and summary_en and len(summary_kr) >= 10 and len(summary_en) >= 10:
            return {
                "summary_kr": summary_kr,
                "summary_en": summary_en
            }
        
        return None

    @cache_response()
    async def generate_tweets(self, insights: Dict, count: int = 5) -> List[str]:
        """
        ì¸ì‚¬ì´íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ íŠ¸ìœ— ì´ˆì•ˆ ìƒì„±
        Returns: List of tweet drafts
        """
        summary = insights.get('summary_kr', insights.get('summary_en', 'ìµœì‹  íŠ¸ë Œë“œ'))
        
        # ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ - JSON ì‘ë‹µ ê°•ì œ
        prompt = f"""ë‹¤ìŒ íŠ¸ë Œë“œ ì¸ì‚¬ì´íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ {count}ê°œì˜ íŠ¸ìœ— ì´ˆì•ˆì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

ì¸ì‚¬ì´íŠ¸:
{summary}

ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
  "tweets": [
    "ì²« ë²ˆì§¸ íŠ¸ìœ— ë‚´ìš©",
    "ë‘ ë²ˆì§¸ íŠ¸ìœ— ë‚´ìš©",
    ...
  ]
}}

íŠ¸ìœ— ì‘ì„± ê°€ì´ë“œ:
- ê° íŠ¸ìœ—ì€ 280ì ì´ë‚´
- ë…ì°½ì ì´ê³  ë§¤ë ¥ì ì¸ ë‚´ìš©
- í•´ì‹œíƒœê·¸ëŠ” ìµœëŒ€ 2-3ê°œë§Œ í¬í•¨
- ê° íŠ¸ìœ—ì€ ì„œë¡œ ë‹¤ë¥¸ ê´€ì ì´ë‚˜ í¬ì¸íŠ¸ë¥¼ ë‹¤ë£¨ê¸°
- ì´ëª¨ì§€ë¥¼ ì ì ˆíˆ í™œìš©í•˜ì—¬ ì‹œê°ì  ë§¤ë ¥ ì¶”ê°€
- í–‰ë™ì„ ìœ ë„í•˜ëŠ” CTA í¬í•¨ ê³ ë ¤"""

        try:
            # OpenAI API ì‹œë„
            if self.openai_api_key:
                result = await retry_with_backoff(
                    lambda: self._call_openai(prompt, model="gpt-4o-mini")
                )
                if result and "OpenAI API key" not in result:
                    tweets = self._parse_tweets(result, count)
                    if tweets:
                        return tweets
            
            # Claude API ì‹œë„
            if self.claude_api_key:
                result = await retry_with_backoff(
                    lambda: self._call_claude(prompt, model="claude-3-5-sonnet-20241022")
                )
                if result and "Claude API key" not in result:
                    tweets = self._parse_tweets(result, count)
                    if tweets:
                        return tweets
        except Exception as e:
            logger.error(f"íŠ¸ìœ— ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)

        # API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ë”ë¯¸ ë°ì´í„° ë°˜í™˜
        logger.warning("AI API í˜¸ì¶œ ì‹¤íŒ¨, ë”ë¯¸ íŠ¸ìœ— ë°˜í™˜")
        return self._get_dummy_tweets(summary, count)
    
    def _parse_tweets(self, text: str, count: int) -> Optional[List[str]]:
        """AI ì‘ë‹µì—ì„œ íŠ¸ìœ— ëª©ë¡ íŒŒì‹± (JSON ìš°ì„ )"""
        try:
            # JSON íŒŒì‹± ì‹œë„
            text = text.strip()
            if "```json" in text:
                text = text.split("```json")[1].split("```")[0].strip()
            elif "```" in text:
                text = text.split("```")[1].split("```")[0].strip()
            
            data = json.loads(text)
            
            # Pydantic ëª¨ë¸ë¡œ ê²€ì¦
            validated = TweetResponse(**data)
            return validated.tweets[:count]
        except (json.JSONDecodeError, ValueError) as e:
            logger.warning(f"JSON íŒŒì‹± ì‹¤íŒ¨, í…ìŠ¤íŠ¸ íŒŒì‹± ì‹œë„: {e}")
            # í´ë°±: í…ìŠ¤íŠ¸ ê¸°ë°˜ íŒŒì‹±
            return self._parse_tweets_text(text, count)
    
    def _parse_tweets_text(self, text: str, count: int) -> Optional[List[str]]:
        """í…ìŠ¤íŠ¸ ê¸°ë°˜ íŠ¸ìœ— íŒŒì‹± (í´ë°±)"""
        tweets = []
        lines = text.split('\n')
        
        for line in lines:
            line = line.strip()
            # ë²ˆí˜¸ë‚˜ ë¶ˆí•„ìš”í•œ ì ‘ë‘ì‚¬ ì œê±°
            if line and len(line) > 10:
                # "íŠ¸ìœ— 1:", "1.", "-" ë“±ì˜ íŒ¨í„´ ì œê±°
                for prefix in ["íŠ¸ìœ—", "Tweet", "1.", "2.", "3.", "4.", "5.", "-", "â€¢", "*"]:
                    if line.startswith(prefix):
                        line = line[len(prefix):].strip()
                        if line.startswith(":"):
                            line = line[1:].strip()
                        break
                
                if line and 10 <= len(line) <= 280:  # íŠ¸ìœ— ê¸¸ì´ ì œí•œ
                    tweets.append(line)
                    if len(tweets) >= count:
                        break
        
        return tweets if tweets else None

    @cache_response()
    async def generate_instagram_post(self, insights: Dict) -> Dict:
        """
        ì¸ì‚¬ì´íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¸ìŠ¤íƒ€ê·¸ë¨ ìº¡ì…˜ + í•´ì‹œíƒœê·¸ ìƒì„±
        Returns: {caption: str, hashtags: List[str]}
        """
        summary = insights.get('summary_kr', insights.get('summary_en', 'ìµœì‹  ë™í–¥ì„ ë¶„ì„í–ˆìŠµë‹ˆë‹¤.'))
        
        # ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ - JSON ì‘ë‹µ ê°•ì œ
        prompt = f"""ë‹¤ìŒ íŠ¸ë Œë“œ ì¸ì‚¬ì´íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¸ìŠ¤íƒ€ê·¸ë¨ í¬ìŠ¤íŠ¸ ìº¡ì…˜ê³¼ í•´ì‹œíƒœê·¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

ì¸ì‚¬ì´íŠ¸:
{summary}

ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
  "caption": "ìº¡ì…˜ ë‚´ìš© (ì´ëª¨ì§€ í¬í•¨)",
  "hashtags": ["í•´ì‹œíƒœê·¸1", "í•´ì‹œíƒœê·¸2", "í•´ì‹œíƒœê·¸3", ...]
}}

ì‘ì„± ê°€ì´ë“œ:
- ìº¡ì…˜ì€ 500-1000ì ì •ë„ë¡œ ì‘ì„±
- ì´ëª¨ì§€ë¥¼ ì ì ˆíˆ ì‚¬ìš©í•˜ì—¬ ì‹œê°ì  ë§¤ë ¥ ì¶”ê°€
- í•´ì‹œíƒœê·¸ëŠ” 5-10ê°œ ì •ë„, ê´€ë ¨ì„± ë†’ì€ ê²ƒë§Œ
- ìŠ¤í† ë¦¬í…”ë§ ìš”ì†Œ í¬í•¨
- ë…ìì˜ ì°¸ì—¬ë¥¼ ìœ ë„í•˜ëŠ” ì§ˆë¬¸ì´ë‚˜ CTA í¬í•¨"""

        try:
            # Claude API ìš°ì„  ì‚¬ìš© (ì¸ìŠ¤íƒ€ê·¸ë¨ í¬ìŠ¤íŠ¸ì— ë” ì í•©)
            if self.claude_api_key:
                result = await retry_with_backoff(
                    lambda: self._call_claude(prompt, model="claude-3-5-sonnet-20241022")
                )
                if result and "Claude API key" not in result:
                    parsed = self._parse_instagram_post(result)
                    if parsed:
                        return parsed
            
            # OpenAI API ì‹œë„
            if self.openai_api_key:
                result = await retry_with_backoff(
                    lambda: self._call_openai(prompt, model="gpt-4o-mini")
                )
                if result and "OpenAI API key" not in result:
                    parsed = self._parse_instagram_post(result)
                    if parsed:
                        return parsed
        except Exception as e:
            logger.error(f"ì¸ìŠ¤íƒ€ê·¸ë¨ í¬ìŠ¤íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)

        # API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ë”ë¯¸ ë°ì´í„° ë°˜í™˜
        logger.warning("AI API í˜¸ì¶œ ì‹¤íŒ¨, ë”ë¯¸ ì¸ìŠ¤íƒ€ê·¸ë¨ í¬ìŠ¤íŠ¸ ë°˜í™˜")
        return self._get_dummy_instagram_post(summary)
    
    def _parse_instagram_post(self, text: str) -> Optional[Dict]:
        """AI ì‘ë‹µì—ì„œ ì¸ìŠ¤íƒ€ê·¸ë¨ ìº¡ì…˜ê³¼ í•´ì‹œíƒœê·¸ íŒŒì‹± (JSON ìš°ì„ )"""
        try:
            # JSON íŒŒì‹± ì‹œë„
            text = text.strip()
            if "```json" in text:
                text = text.split("```json")[1].split("```")[0].strip()
            elif "```" in text:
                text = text.split("```")[1].split("```")[0].strip()
            
            data = json.loads(text)
            
            # Pydantic ëª¨ë¸ë¡œ ê²€ì¦
            validated = InstagramPostResponse(**data)
            return {
                "caption": validated.caption,
                "hashtags": validated.hashtags
            }
        except (json.JSONDecodeError, ValueError) as e:
            logger.warning(f"JSON íŒŒì‹± ì‹¤íŒ¨, í…ìŠ¤íŠ¸ íŒŒì‹± ì‹œë„: {e}")
            # í´ë°±: í…ìŠ¤íŠ¸ ê¸°ë°˜ íŒŒì‹±
            return self._parse_instagram_post_text(text)
    
    def _parse_instagram_post_text(self, text: str) -> Optional[Dict]:
        """í…ìŠ¤íŠ¸ ê¸°ë°˜ ì¸ìŠ¤íƒ€ê·¸ë¨ í¬ìŠ¤íŠ¸ íŒŒì‹± (í´ë°±)"""
        caption = ""
        hashtags = []
        
        # ìº¡ì…˜ ì¶”ì¶œ
        if "caption" in text:
            parts = text.split('"caption"')
            if len(parts) > 1:
                caption_part = parts[1].split('"hashtags"')[0].strip(' :,"')
                caption = caption_part
        elif "ìº¡ì…˜:" in text:
            parts = text.split("ìº¡ì…˜:")
            if len(parts) > 1:
                caption_part = parts[1].split("í•´ì‹œíƒœê·¸:")[0].strip()
                caption = caption_part
        
        # í•´ì‹œíƒœê·¸ ì¶”ì¶œ
        if "hashtags" in text:
            parts = text.split('"hashtags"')
            if len(parts) > 1:
                hashtag_text = parts[1].strip(' :,[]{}')
                for tag in hashtag_text.split(','):
                    tag = tag.strip(' "\'#[]')
                    if tag:
                        hashtags.append(tag)
        elif "í•´ì‹œíƒœê·¸:" in text:
            parts = text.split("í•´ì‹œíƒœê·¸:")
            if len(parts) > 1:
                hashtag_text = parts[1].strip()
                for tag in hashtag_text.split():
                    tag = tag.strip("#[]")
                    if tag:
                        hashtags.append(tag)
        
        if caption and len(caption) >= 50:
            return {
                "caption": caption,
                "hashtags": hashtags if hashtags else ["íŠ¸ë Œë“œë¶„ì„", "ì¸ì‚¬ì´íŠ¸", "ë°ì´í„°ë¶„ì„"]
            }
        
        return None

    async def _call_openai(self, prompt: str, model: str = "gpt-4o-mini") -> str:
        """OpenAI API í˜¸ì¶œ"""
        if not self.openai_api_key:
            return "OpenAI API keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        
        try:
            from openai import OpenAI
            
            client = OpenAI(api_key=self.openai_api_key)
            
            response = client.chat.completions.create(
                model=model,
                messages=[
                    {
                        "role": "system",
                        "content": "You are an expert social media analyst and content creator. You analyze trends and create engaging, high-quality content. Always respond in valid JSON format when requested."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=settings.ai_temperature,
                max_tokens=settings.ai_max_tokens,
                response_format={"type": "json_object"}  # JSON ëª¨ë“œ ê°•ì œ
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            logger.error(f"OpenAI API í˜¸ì¶œ ì˜¤ë¥˜: {e}", exc_info=True)
            raise

    async def _call_claude(self, prompt: str, model: str = "claude-3-5-sonnet-20241022") -> str:
        """Claude API í˜¸ì¶œ"""
        if not self.claude_api_key:
            return "Claude API keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        
        try:
            import anthropic
            
            client = anthropic.Anthropic(api_key=self.claude_api_key)
            
            response = client.messages.create(
                model=model,
                max_tokens=settings.ai_max_tokens,
                temperature=settings.ai_temperature,
                messages=[
                    {
                        "role": "user",
                        "content": prompt
                    }
                ]
            )
            
            return response.content[0].text.strip()
            
        except Exception as e:
            logger.error(f"Claude API í˜¸ì¶œ ì˜¤ë¥˜: {e}", exc_info=True)
            raise
    
    # ë”ë¯¸ ë°ì´í„° ìƒì„± ë©”ì„œë“œë“¤
    def _get_dummy_insights(self, tweet_count: int) -> Dict:
        """ë”ë¯¸ ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        summary_kr = f"ìµœê·¼ {tweet_count}ê°œì˜ íŠ¸ìœ—ì„ ë¶„ì„í•œ ê²°ê³¼, ì£¼ìš” íŠ¸ë Œë“œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n\n"
        summary_kr += "- ì‚¬ìš©ìë“¤ì´ ê³µìœ í•˜ëŠ” ì£¼ìš” ì£¼ì œë“¤ì´ í™•ì¸ë©ë‹ˆë‹¤.\n"
        summary_kr += "- ê°ì •ì  ë°˜ì‘ê³¼ ì°¸ì—¬ë„ê°€ ë†’ì€ ê²Œì‹œë¬¼ë“¤ì´ ëˆˆì— ë•ë‹ˆë‹¤.\n"
        summary_kr += "- ìƒˆë¡œìš´ ê´€ì ê³¼ ì˜ê²¬ë“¤ì´ ë‹¤ì–‘í•˜ê²Œ ì œì‹œë˜ê³  ìˆìŠµë‹ˆë‹¤."
        
        summary_en = f"After analyzing {tweet_count} recent tweets, the main trends are:\n\n"
        summary_en += "- Key topics shared by users have been identified.\n"
        summary_en += "- Posts with high emotional engagement stand out.\n"
        summary_en += "- Diverse perspectives and opinions are being presented."

        return {
            "summary_kr": summary_kr,
            "summary_en": summary_en
        }
    
    def _get_dummy_tweets(self, summary: str, count: int) -> List[str]:
        """ë”ë¯¸ íŠ¸ìœ— ìƒì„±"""
        tweet_list = []
        for i in range(count):
            tweet_list.append(
                f"ğŸ“Š íŠ¸ë Œë“œ ë¶„ì„ #{i+1}: {summary[:100]}... "
                f"ë” ë§ì€ ì¸ì‚¬ì´íŠ¸ë¥¼ í™•ì¸í•´ë³´ì„¸ìš”! #íŠ¸ë Œë“œ #ì¸ì‚¬ì´íŠ¸"
            )
        return tweet_list[:count]
    
    def _get_dummy_instagram_post(self, summary: str) -> Dict:
        """ë”ë¯¸ ì¸ìŠ¤íƒ€ê·¸ë¨ í¬ìŠ¤íŠ¸ ìƒì„±"""
        caption = f"""ğŸ“ˆ ìµœì‹  íŠ¸ë Œë“œ ì¸ì‚¬ì´íŠ¸

{summary[:200]}

ë” ë§ì€ ì¸ì‚¬ì´íŠ¸ì™€ ë¶„ì„ ê²°ê³¼ë¥¼ í™•ì¸í•´ë³´ì„¸ìš”!

ì–´ë–¤ íŠ¸ë Œë“œê°€ ê°€ì¥ í¥ë¯¸ë¡œìš°ì‹ ê°€ìš”? ëŒ“ê¸€ë¡œ ì•Œë ¤ì£¼ì„¸ìš”! ğŸ‘‡"""

        hashtags = [
            "íŠ¸ë Œë“œë¶„ì„",
            "ì¸ì‚¬ì´íŠ¸",
            "ë°ì´í„°ë¶„ì„",
            "ì†Œì…œë¯¸ë””ì–´",
            "ë§ˆì¼€íŒ…"
        ]

        return {
            "caption": caption,
            "hashtags": hashtags
        }
